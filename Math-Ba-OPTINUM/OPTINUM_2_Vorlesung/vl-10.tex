\documentclass[german]{scrreprt}

\usepackage[top=2.5cm,bottom=2.5cm,left=2.5cm,right=2.5cm]{geometry}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
%\setlength{\parindent}{0pt}
\usepackage{parskip}

\usepackage{lmodern}
\usepackage{color}
\usepackage[ngerman]{babel}
\usepackage{csquotes}

\usepackage[scale=0.95]{opensans}	% new font OpenSans
\newcommand*{\osfamily}{\fontfamily{fos}\selectfont}
\DeclareTextFontCommand{\textos}{\fosfamily}

\let\emph\textbf
\newcommand{\begriff}[1]{\textbf{#1}}

\addtokomafont{disposition}{\fosfamily}
\addtokomafont{chapter}{\Huge}
\addtokomafont{section}{\LARGE}
\addtokomafont{subsection}{\Large}

\usepackage{scrlayer-scrpage}
\usepackage[linesnumbered,inoutnumbered]{algorithm2e}
%\usepackage[defernumbers=true,
%            maxbibnames=99,  % Never write 'et al.' in a bibliography
%            giveninits=true, % Abbreviate first names
%            sortcites=true,  % Sort citations when there are more than one
%            natbib=true,     % Allow commands like \citet and \citep
%            backend=biber]{biblatex}
%\addbibresource{skript-numerik-sander.bib}

\usepackage[makeroom]{cancel}


\usepackage{enumerate}
\usepackage[inline]{enumitem} 		%customize label

\renewcommand{\labelitemi}{\raisebox{1pt}{\scalebox{.5}{$\blacksquare$}}}
\renewcommand{\labelitemii}{$\vartriangleright$}
\renewcommand{\labelitemiii}{--}
% Variantionen des Dreiecks als Aufzählungszeichen $\blacktriangleright$ / $\vartriangleright$ / $\triangleright$

%\renewcommand{\labelenumi}{(\alph{enumi})}
%\renewcommand{\labelenumii}{\roman{enumii}.}
%\renewcommand{\labelenumiii}{\roman{enumiii}.}



\usepackage{microtype}
\usepackage{todonotes}
\usepackage{pdfcomment}  % todonotes without tikz -- the two don't play well together
\newcommand{\todoannot}[2]{
  \pdffreetextcomment[width=\textwidth,height=#1,color=orange]{#2}
}

\usepackage{xcolor}
\usepackage[table,dvipsnames]{tudscrcolor}

\usepackage{esdiff}
\usepackage{url}
\usepackage{overpic}
\usepackage{hyperref}
\usepackage{array}
\usepackage{tikz}
\usetikzlibrary{arrows,calc,cd,decorations.pathmorphing,matrix,patterns,positioning,shapes}
\usepackage{graphicx}
\usepackage{float}


\usepackage{pgfplots}
\usepgfplotslibrary{fillbetween,colormaps}
\pgfplotsset{compat=newest}


\usepackage[ntheorem,framemethod=TikZ]{mdframed}
\usepackage{amsmath,amssymb,amsfonts,mathtools}
\usepackage[amsmath,thmmarks,framed]{ntheorem}
\usepackage{colonequals}
\usepackage{wasysym}

% allow to smash underbraces:
% use \smashedUnderbrace instead of \underbrace
% surround formula with \reboxSmashedUnderbraces
% https://web.archive.org/web/20160820203342/http://tex.stackexchange.com/questions/38930/ignoring-vertical-space-due-to-underbraces-in-cases-environment
\newcommand\realSmashC[1]{\smash{\mathclap{#1}}}
\newcommand\realSmashR[1]{\smash{\mathrlap{#1}}}
\newcommand\smashedUnderbrace[2]{\underbrace{#1}_{#2}}
\newcommand\actualSmashUnderbrace[2]{%
	\realSmashR{\underbrace{#1}_{\realSmashC{#2}}} \phantom{#1}}
\newcommand\reboxSmashedUnderbraces[1]{%
	{\renewcommand{\smashedUnderbrace}{\actualSmashUnderbrace}#1}%
	\vphantom{#1}}

\allowdisplaybreaks[0]


\newcommand{\R}{\mathbb R}
\newcommand{\N}{\mathbb N}
\newcommand{\K}{\mathbb K}
\renewcommand{\C}{\mathbb C}
\newcommand{\D}{\mathcal{D}}
\newcommand{\spann}{\operatorname{span}}
\newcommand{\extendadd}{\;\; \updownarrow \hspace{-12pt} \longleftrightarrow}
\newcommand{\qq}[1]{\glqq #1\grqq}

\renewcommand{\Re}{\operatorname{Re}}
\renewcommand{\Im}{\operatorname{Im}}

\newcommand{\abs}[1]{\lvert #1 \rvert}
\newcommand{\norm}[1]{\lVert #1 \rVert}


\newcommand{\skiparound}{10pt}

\theoremstyle{plain}
\theoremheaderfont{\osfamily\normalsize\bfseries\upshape}
\theorembodyfont{\normalsize}
\theoremseparator{.}
\theoremsymbol{}


\newmdtheoremenv[%
	%style=boxedtheorem,%
	backgroundcolor=cdblue!10,%
	linecolor=cddarkblue!90,%
	%innertopmargin=\boxskip,%
	%innerbottommargin=\boxskip,%
	innerleftmargin=4pt,%
	outerlinewidth=5pt,%
	topline=false,%
	rightline=true,%
	leftline=false,%
	bottomline=false,%
	%innertopmargin=3pt,%
	%innerbottommargin=3pt,%
	leftmargin=-4pt,%
	%rightmargin=-10pt,%
	skipabove=\skiparound,%
	skipbelow=\skiparound,%
	nobreak,%
]{satz}{Satz}

\newmdtheoremenv[%
	%style=boxedtheorem,%
	backgroundcolor=cdindigo!5,%
	linecolor=cdindigo!50,%
	%innertopmargin=\boxskip,%
	%innerbottommargin=\boxskip,%
	innerleftmargin=4pt,%
	outerlinewidth=5pt,%
	topline=false,%
	rightline=true,%
	leftline=false,%
	bottomline=false,%
	%innertopmargin=3pt,%
	%innerbottommargin=3pt,%
	leftmargin=-4pt,%
	%rightmargin=-10pt,%
	%frametitlefont=\osfamily\bfseries,%
	%skipabove=5pt,%
	%skipbelow=5pt,%
	skipabove=\skiparound,%
	skipbelow=\skiparound,%
	nobreak,%
]{lemma}{Lemma}


\theoremstyle{nonumberplain}

\newmdtheoremenv[%
	%style=boxedtheorem,%
	backgroundcolor=cdorange!10,%
	linecolor=cdorange,%
	%innertopmargin=\boxskip,%
	%innerbottommargin=\boxskip,%
	innerleftmargin=4pt,%
	outerlinewidth=5pt,%
	topline=false,%
	rightline=true,%
	leftline=false,%
	bottomline=false,%
	%innertopmargin=3pt,%
	%innerbottommargin=3pt,%
	leftmargin=-4pt,%
	%rightmargin=-10pt,%
	%frametitlefont=\osfamily\bfseries,%
	%skipabove=5pt,%
	%skipbelow=5pt,%
	skipabove=\skiparound,%
	skipbelow=\skiparound,%
	nobreak,%
]{defi}{Definition}

\newmdtheoremenv[%
	%style=boxedtheorem,%
	backgroundcolor=cdorange!10,%
	linecolor=cdorange,%
	%innertopmargin=\boxskip,%
	%innerbottommargin=\boxskip,%
	innerleftmargin=4pt,%
	outerlinewidth=5pt,%
	topline=false,%
	rightline=true,%
	leftline=false,%
	bottomline=false,%
	%innertopmargin=3pt,%
	%innerbottommargin=3pt,%
	leftmargin=-4pt,%
	%rightmargin=-10pt,%
	%frametitlefont=\osfamily\bfseries,%
	%skipabove=5pt,%
	%skipbelow=5pt,%
	skipabove=\skiparound,%
	skipbelow=\skiparound,%
	nobreak,%
]{definition}{Definition}


\theoremstyle{nonumberplain}
\theorempreskip{\skiparound}
\theorempostskip{\skiparound}

\newtheorem{bsp}{Beispiel}
\newtheorem{algo}{Algorithmus}
\newtheorem{folg}{Folgerung}
\newtheorem{kor}{Korollar}

\theoremheaderfont{\normalfont \bfseries}
\theorembodyfont{\itshape}
\newtheorem{bem}{Bemerkung}
\newtheorem{hinw}{Hinweis}

\theoremheaderfont{\normalfont \bfseries}
\newtheorem{idea}{Idee}
\newtheorem{aim}{Ziel}
\newtheorem{question}{Frage}

\theorembodyfont{}
\newtheorem{aufw}{Aufwand}

\newtheorem{vSfS}{vSfS}

%\newtheoremstyle{proofstyle}%
%{\item[\hskip\labelsep {\theorem@headerfont ##1}\theorem@separator]}%
%{\item[\hskip\labelsep {\theorem@headerfont ##1}\ (##3)\theorem@separator]}

\theoremstyle{nonumberplain}
\theoremheaderfont{\normalsize\slshape}
\theorembodyfont{}
\theoremseparator{.}
\theorempreskip{0pt}
\theorempostskip{5pt}
\theoremsymbol{$\square$}
\newtheorem{proof}{Beweis}

\usepackage{chngcntr}
\counterwithin{satz}{chapter}
\counterwithin{lemma}{chapter}

%\pagestyle{scrheadings}
%\clearscrheadings
%\ihead{Mathematik}
%\chead{\textbf{Numerik}}
%\ohead{Prof.~Dr.~O.\,Sander}
%\setheadsepline{0.4pt}
\cfoot{\pagemark}

%%  All graphics files may be in this subdirectory
\graphicspath{{gfx/}}
%\includeonly{numerische-quadratur}
\begin{document}

%\frontmatter

%\begin{titlepage}
%	\pagecolor{cddarkblue!90} \color{white}%
%	\raggedright \fosfamily%
%	\setlength{\parindent}{0pt}% 
%	% Logo / Kopf
%	\hspace{-18.6mm} %
%	\includegraphics[scale=0.6]{TUD-white.pdf} \\
%	\vspace{3mm} 
%	\begin{tabular}{m{\textwidth}}
%		\hline
%		\hspace{-4pt}\small{\textbf{Fakultät Mathematik} Institut für Numerik, Professur für Numerik partieller Differentialgleichungen} \\
%		\hline
%	\end{tabular} \\
%	% Titel
%	\vspace{5cm}
%	{\Huge\bfseries \MakeUppercase Optimierung \& Numerik --- Teil 2 \par}
%		\vspace{0.5cm}%
%		{\Large \itshape Numerik gewöhnlicher Differentialgleichungen} \\%
%	\vspace{1.5cm}
%	\textbf{{\Large Prof. Dr. Oliver Sander}} \par
%	\vspace{0.5cm}
%	{\large Sommersemester 2020} \par
%	
%	\vspace{1.5cm}
%	
%	
%	\vfill%
%	% Fußzeile
%	\begin{tabular}{lll}
%		Name  & : & Eric Kunze \\
%		E-Mail & : & \url{eric.kunze@mailbox.tu-dresden.de} \\
%		Datum & : & \today
%	\end{tabular}%
%\end{titlepage}
%\nopagecolor
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%  Copyright notice
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\vspace*{\fill}
%
%\begin{center}
%	\slshape
%	Das vorliegende Skript basiert nahezu vollständig auf dem Vorlesungsskript von Prof. Dr. Oliver Sander für die Vorlesung \enquote{Optimierung und Numerik} an der Technischen Universität Dresden. Das aktuelle Original ist unter \\ \url{https://gitlab.mn.tu-dresden.de/osander/skript-numerik} \\
%	zu finden.
%\end{center}
%
%\vspace*{\fill}
%
%\pagebreak


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\renewcommand*\contentsname{\huge \centering Optimierung \& Numerik --- Vorlesung 10}
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\setcounter{chapter}{11}
\setcounter{section}{6}
\setcounter{satz}{15}
\setcounter{lemma}{13}
\setcounter{equation}{3}

\section{Linear-implizite Einschrittverfahren}

Wir haben Verfahren konstruiert, die hohe Ordnung haben, und trotzdem $A$-stabil sind, z.B. das Gauß-Verfahren; es gibt aber noch andere.
Diese Verfahren sind implizit. Zum Berechnen des nächsten Zeitschritts muss ein Gleichungssystem gelöst werden.
\begin{itemize}
	\item Falls $f$ linear ist, so ist dieses Gleichungssystem linear. Das ist okay.
	\item Falls $f$ nichtlinear ist, so ist Gleichungssysteme ebenfalls nichtlinear. Das kann ganz schön teuer werden!
\end{itemize}
Können wir $A$-stabile Verfahren konstruieren, für die bei jedem Schritt nur ein lineares Gleichungssystem gelöst werden muss, selbst wenn $f$ nichtlinear ist?

\subsection{Stabilität von Fixpunkten}

Wir wollen einen alternativen Stabilitätsbegriff für autonome
nichtlineare Differentialgleichungen $x'=f(x)$ untersuchen.

\begin{definition}
	Ein Zustand $x_* \in \Omega_0$ heißt Fixpunkt der Gleichung, wenn $f(x_*)=0$, bzw. wenn $\Phi^tx_* = x_*$ für alle $t$ ist.
\end{definition}
\begin{definition}
	Ein Fixpunkt $x_*$ heißt asymptotisch stabil, wenn ein $\epsilon>0$ existiert, so dass $\lim_{t \to \infty} \Phi^t x_0 = x_*$ für alle $x_0 \in \Omega_0$ mit $\norm{x_* - x_0} < \epsilon$.
\end{definition}

\begin{bsp} ~
	\begin{center}
		\begin{tikzpicture}
		\draw[->] (0,-1) node[right]{$x_*$ asymptotisch stabil} -- (0,4) ;
		\draw[->] (-1,0) -- (4,0) node[right]{$t$};
		\foreach \i in {0,...,3}
		{
			\foreach \j in {0,...,7}
			{
				\draw[->] (\i,\j / 2) -- (\i + 0.8,\j / 4 + 1) ;
			}
		}
		\draw (0,2) node[left]{$x_*$};
		\end{tikzpicture}
		%
		\hspace{0.1\textwidth}%
		%
		\begin{tikzpicture}
		\draw[->] (0,-1) node[right]{$x_*$ instabil} -- (0,4) ;
		\draw[->] (-1,0) -- (4,0) node[right]{$t$};
		\foreach \i in {0,...,3}
		{
			\foreach \j in {0,...,7}
			{
				\draw[->] (\i,\j / 4 + 1) -- (\i + 0.8,\j / 2) ;
			}
		}
		\draw (0,2) node[left]{$x_*$};
		\end{tikzpicture}
	\end{center}
	Man erkennt an den Bildern, dass die asymptotische Stabilität von $x_*$ mit der Ableitung von $f$ in (der Nähe von) $x_*$ zusammenhängt. 
\end{bsp}


\begin{satz}[{{\cite[3.30]{deuflhard_bornemann:2008}}}]
	Sei $x_* \in \Omega_0$ Fixpunkt von $x' = f(x)$, und $f$ sei stetig differenzierbar. Falls
	\begin{equation*}
	\nu(Df(x_*)) < 0
	\end{equation*}
	so ist $x_*$ asymptotisch stabiler Fixpunkt
\end{satz}

\textbf{Erinnerung:} $\nu$ ist die Spektralabzisse, der größte Realteil aller Eigenwerte.

\textbf{Zwischenfazit:} Um die asymptotische Stabilität von Fixpunkten zu untersuchen, reicht es, sich die Linearisierung um $ x_* $ anzuschauen!

Wir betrachten jetzt zusätzlich die um $ x_* $ linearisierte Differentialgleichung
\begin{equation}\label{Gleichung:Linearisierte-Differentialgleichung}
(x-x_*)' = x' = Df(x_*)(x-x_*).
\end{equation}

\begin{idea}
	Wenn $Df(x_*)$ das Stabilitätsverhalten von $x_*$ qualitativ richtig beschreibt, dann enthält die \emph{lineare} Gleichung~\eqref{Gleichung:Linearisierte-Differentialgleichung}
	vielleicht schon alle \enquote{schwierigen} (im Sinne der Stabilität) Aspekte von $ x'=f(x)$ in der Nähe von $ x_* $?
\end{idea}

Betrachte ein beliebiges Einschrittverfahren. Sei
\begin{itemize}
	\item $\Psi^\tau$ diskreter Fluss für das Ausgangsproblem
	\item $\Psi_*^\tau$ diskreter Fluss für das linearisierte Problem $x'=Df(x_*)(x-x_*)$.
\end{itemize}

\begin{definition}
	Ein Einschrittverfahren heißt \begriff{invariant gegen Linearisierung} um einen Fixpunkt $x_*$, wenn
	\begin{enumerate}
		\item $\Psi^\tau x_*=x_*\ \forall\tau>0$ ($\tau$ zulässig)
		$\qquad \rightarrow$ der Fixpunkt der Differentialgleichung ist auch
		Fixpunkt des numerischen Verfahrens für die nichtlineare Gleichung.
		
		\item $\Psi_*^\tau x = x_* + R(\tau Df(x_*))(x-x_*)$ mit einer rationalen Funktion $R$, die nur vom Verfahren abhängt; d.h. für das linearisierte Problem degeneriert das Verfahren zu einer rationalen Approximation der Exponentialfunktion.
		
		\item $D_x\Psi^\tau x\vert_{x=x_*}=\Psi^\tau_*$ für alle zulässigen $\tau$ $\qquad \rightarrow$ $\Psi^\tau_*$ ist Linearisierung von $\Psi^\tau$.
	\end{enumerate}
\end{definition}

Zum Beispiel sind alle expliziten RK-Verfahren in diesem Sinne invariant. Solch ein Verfahren heißt $A$-stabil, falls $R$ $A$-stabil ist.

Invariante Verfahren retten den Zusammenhang zwischen der asymptotischen Stabilität eines Fixpunkts $x_*$ und der Linearisierung dort ins Diskrete:

\begin{satz}[{{\cite[6.23]{deuflhard_bornemann:2008}}}]
	Sei $\Psi^\tau$, $\Psi^\tau_*$ ein gegen Linearisierung invariantes Einschrittverfahren. Sei $\tau_c\geq 0$ die maximale Schrittweite, so dass $\Psi^\tau_*$ die asymptotische Stabilität erbt. Dann ist $x_*$ asymptotisch stabiler Fixpunkt der Rekursion
	\begin{equation*}
	x_{n+1} = \Psi^\tau x_n\qquad n=0,1,2,\hdots
	\end{equation*}
	für alle $\tau<\tau_c$.
\end{satz}

\begin{bsp}
	Skalare Differentialgleichung $x' = \lambda(1-x^2) \qquad (\lambda > 0)$
	\begin{itemize}
		\item Fixpunkte: $ x_s = 1$ (asymptotisch stabil) und $x_u = -1$ instabil	
		\item Linearisierte Gleichung in $x_s$:
		\begin{equation*}
		x' = f'(x_s)(x-x_s) = -2\lambda x_s(x-x_s) = -2\lambda(x-1)
		\end{equation*}
		\item Explizites Euler-Verfahren dafür stabil, wenn $\tau< 1/\lambda$
		\item Es folgt: $x_s$ ist auch asymptotisch stabiler Fixpunkt des expliziten Euler-Verfahrens für die nichtlineare Gleichung
		\begin{equation*}
		x_{n+1} = x_n + \tau f(x_n) = x_n + \tau\lambda(1-x_n^2).
		\end{equation*}
		Aber wie gesagt nur falls $\tau< 1/\lambda$.
	\end{itemize}
	Und nicht vergessen: $x_s$ ist nur dann Attraktor, wenn man nah genug dran startet. Für dieses Beispiel heißt das:
	\begin{itemize}
		\item Kontinuierlich: $x_0>-1$
		\item Euler: $x_0\in[0, \frac{5}{4}]$.
	\end{itemize}
\end{bsp}

\subsection{Linear-implizite Runge--Kutta-Verfahren}

\begin{idea}
	Behandle nur den linearen Teil von $f$ implizit.
\end{idea}

Für festes $\bar{x} \in \Omega_0$ schreibe die Differentialgleichung als
\begin{equation*}
x'(t) = Jx(t) + (f(x(t)) - Jx(t)) \qquad J=Df(\bar{x})\in\R^{d\times d}
\end{equation*}
Hier ist $\bar{x}$ beliebig; in der Praxis linearisiert man um den Zustand
zum vorigen Zeitschritt.

Wende das implizite Euler-Verfahren auf den ersten Term an, und das explizite Euler-Verfahren auf den Rest.
\begin{equation*}
\Psi^\tau x = \xi + \tau(f(x)-Jx),\qquad \xi = x+\tau J\xi
\end{equation*}
Das ist das linear-implizite oder \begriff{semi-implizite Euler-Verfahren}.
Wir haben nur ein \textit{lineares} Gleichungssystem pro Schritt, aber sind trotzdem $A$-stabil.

Betrachten wir nun allgemein \begriff{linear-implizite Runge-Kutta-Verfahren}
\begin{equation*}
\Psi^\tau x = x + \tau \sum_{j=1}^s b_j k_j
\end{equation*}
\begin{equation*}
k_i = J\Big(x+\tau\sum_{j=1}^i \beta_{ij} k_j\Big)
+ \bigg[ f\Big(x+\tau\sum_{j=1}^{i-1} \alpha_{ij} k_j\Big)
- J\Big(x+\tau\sum_{j=1}^{i-1} \alpha_{ij} k_j\Big)\bigg]
\end{equation*}
für $i=1,\dots,s$.

\begin{hinw}
	Der obere Summationsindex des impliziten Teils ist $i$, nicht $s$.
\end{hinw}

Dadurch kann der Phasenfluss durch wiederholtes Lösen \textit{linearer} Gleichungssysteme berechnet werden.
\begin{enumerate}
	\item $J = Df(x)$
	\item $\displaystyle (I-\tau\beta_{ii}J)k_i = \tau\sum_{j=1}^{i-1}(\beta_{ij}-\alpha_{ij})Jk_j + f\Big(x + \tau\sum_{j=1}^{i-1} \alpha_{ij} k_j\Big)$ für $i=1,\dots,s$
	\item $\displaystyle \Psi^\tau x = x + \tau\sum_{j=1}^{s} b_j k_j$
\end{enumerate}
Solche Verfahren heißen \begriff{lineare-implizite RK-Verfahren} oder \begriff{Rosenbrock-Verfahren}.


Koeffizienten: $A=(\alpha_{ij})\in\R^{s\times s},\ B=(\beta_{ij})\in\R^{s\times s},\  b=(b_1\hdots,b_s)$

Wählt man die $\beta_{ii}$ alle gleich, so haben die $s$ Gleichungssysteme in (2) alle die gleiche Matrix und es reicht eine LR-Zerlegung, um alle $s$ Gleichungssysteme zu lösen.

Die Frage, ob sich die linearen Gleichungssysteme tatsächlich immer lösen lassen, ist einfacher als für den allgemeinen impliziten Fall:
\begin{lemma}
	Sei $\beta \geq 0$ und $J\in\R^{d\times d}$. Die Matrix $I-\tau\beta J$ ist für alle $0\leq \tau\leq \tau_*$ invertierbar. Dabei hängt $\tau_*$ von der Spektralabzisse $\nu(J)$ ab:
	\begin{equation*}
	\tau_* = \infty\text{ für } \nu(J)\leq 0, \qquad \tau_* =  \frac{1}{\beta\nu(J)} \text{ für }	\nu(J) > 0.
	\end{equation*}
\end{lemma}
\begin{proof}
	Zu zeigen: Unter den gegebenen Voraussetzungen hat $I-\tau\beta J$ nicht den Eigenwert $0$. Nach Satz~\eqref{thm:spektrale_aequivarianz} über rationale Funktionen ist aber
	\begin{equation*}
	\sigma(I-\tau\beta J) = 1-\tau\beta\sigma(J).
	\end{equation*}
	Deshalb zu zeigen: $J$ hat keinen Eigenwert $\lambda$ mit $1-\tau\beta\lambda = 0$.\\
	\begin{enumerate}[label=Fall \arabic*:, leftmargin=*]
		\item $\nu(J) \leq 0$, d.h. insbesondere $\Re(\lambda)\leq 0$:
		\begin{equation*}
		\Re(1-\tau\beta\lambda) = 1-\tau\beta \Re(\lambda) \geq 1 \quad  \Rightarrow \quad 1-\tau\beta\lambda \neq 0
		\end{equation*}
		\item $0<\Re(\lambda)\leq \nu(J)$:
		\begin{equation*}
		\Re(1-\tau\beta\lambda) = 1 - \tau \beta \Re(\lambda) \geq 1 - \tau\beta\nu(J)
		\end{equation*}
		Also $>0$ wenn $\tau < \frac{1}{\beta\nu(J)}$
	\end{enumerate}
\end{proof}

Der Satz sagt also: Die steifen Anteile der Differentialgleichung (d.h. die nichtpositiven Eigenwerte von $J$) beeinflussen nicht die Lösbarkeit des Gleichungssystems.

Für autonome \textit{lineare} Probleme ist das Verfahren offensichtlich äquivalent zum impliziten Runge-Kutta-Verfahren $(b, (\beta_{ij}))$.  Es hat also die selbe Stabilitätsfunktion.

Die Konstruktion der Bedingungsgleichungen funktioniert ähnlich wie bei expliziten RK-Verfahren.


\bibliographystyle{alpha}
\bibliography{skript-numerik-sander}

\end{document}